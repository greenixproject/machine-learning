# -*- coding: utf-8 -*-
"""Greenix_vehicle_emissions

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1h4rQVMNXKZ5LYSoOh8_LjfKLQHA2QUF6
"""

!pip install tensorflow==2.13.0rc1
!pip install tensorflowjs

# Use seaborn for pairplot.
!pip install -q seaborn

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns


# Make NumPy printouts easier to read.
np.set_printoptions(precision=3, suppress=True)

import tensorflow as tf
import tensorflowjs as tfjs
from google.colab import drive
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.models import load_model
from tensorflow.keras.callbacks import ModelCheckpoint
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error
from sklearn.metrics import r2_score
from sklearn.decomposition import PCA

print(tf.__version__)

"""## Vehicle Datast

The dataset is available from the [Greenix Machine Learning Repository](https://docs.google.com/spreadsheets/d/1IJYOS6bOAGhYBRam_2W1_GvcVVHMdZR1/edit?usp=sharing&ouid=111311287901752825886&rtpof=true&sd=true).

### Get the data
First download and import the dataset using pandas:
"""

from google.colab import drive
drive.mount('/content/drive', force_remount=True)

# Menentukan path file CSV yang telah diunggah
url = '/content/drive/MyDrive/Vehicle_Greenix/Dataset/dataset_vehicle.csv'
column_names = ['no',	'car_class',	'fuel_type_car',	'emissions_factor_car',	'distanced_car',	'emissions_car',	'motor_class',	'motor_subclass',	'fuel_type_motor',	'emission_factor_motor',	'distanced_motor',	'emissions_motor',	'bus_class',	'fuel_type_bus',	'emission_factor_bus',	'distanced_bus',	'emissions_bus',	'total_emissions']

# Membaca file CSV ke DataFrame
df = pd.read_csv(url)

# Menampilkan beberapa baris pertama DataFrame
print(df.head())

"""### Clean the data

The dataset contains a few unknown values:
"""

df.info()

# cek data duplikat
df.duplicated().sum()

# Membersihkan data yang tidak lengkap (Jika ada)
df = df.dropna(axis=0)

# Menghapus Kolom yang tidak diperlukan
df = df.drop(['no',	'fuel_type_car',	'emissions_factor_car',	'motor_subclass',	'fuel_type_motor',	'emission_factor_motor',	'fuel_type_bus',	'emission_factor_bus'], axis=1)

df.head()

# Melihat jumlah baris dan kolom
df.shape

# Melihat info statistik data
df.describe()

# Melihat tipe data
print(df.dtypes)

# melihat missing values
df[df==0].count()

#Cek data outlier
num_feat = ['distanced_car',	'emissions_car',	'distanced_motor',	'emissions_motor',	'distanced_bus',	'emissions_bus',	'total_emissions']
cat_feat = ['car_class', 'motor_class', 'bus_class']

for num in num_feat :
  plt.figure(figsize = (10,5))
  sns.boxplot(data = df, x = num, palette = 'Set1')
  plt.figure()

"""**Unvariate Analysis**


"""

# Specify the string (categorical) column
column_name = 'car_class'  # Replace with the actual column name

# Calculate value counts
value_counts = df[column_name].value_counts()

# Create a bar plot of the value counts
plt.figure(figsize=(10, 6))
sns.barplot(x=value_counts.index, y=value_counts.values)
plt.title('Jumlah Pembagian ' + column_name)
plt.xlabel(column_name)
plt.ylabel('Jumlah')
plt.xticks(rotation=45)
plt.show()

# Specify the string (categorical) column
column_name = 'motor_class'  # Replace with the actual column name

# Calculate value counts
value_counts = df[column_name].value_counts()

# Create a bar plot of the value counts
plt.figure(figsize=(10, 6))
sns.barplot(x=value_counts.index, y=value_counts.values)
plt.title('Jumlah Pembagian ' + column_name)
plt.xlabel(column_name)
plt.ylabel('Jumlah')
plt.xticks(rotation=45)
plt.show()

# Specify the string (categorical) column
column_name = 'bus_class'  # Replace with the actual column name

# Calculate value counts
value_counts = df[column_name].value_counts()

# Create a bar plot of the value counts
plt.figure(figsize=(10, 6))
sns.barplot(x=value_counts.index, y=value_counts.values)
plt.title('Jumlah Pembagian ' + column_name)
plt.xlabel(column_name)
plt.ylabel('Jumlah')
plt.xticks(rotation=45)
plt.show()

#Numeric
df.hist(bins = 20, figsize = (15, 15), color = "red", grid = False)
plt.show()

"""# Analisis Data

Pada tfep_kgco2e tidak terdapat user yang memiliki nilai 0 yang berarti seluruh responden melakukan konsumsi dari pilihan makanan sehingga seluruh responden menghasilkan emisi.
Pada makanan jagung terdapat 328 baris yang memiliki nilai 0, sedangkan pada makanan beras terdapat 18 baris yang memiliki nilai 0, pada makanan singkong terdapat 329 baris yang memiliki nilai 0, kemudian pada makanan kacang-kacangan terdapat 310 baris yang memiliki nilai 0, pada makanan daging unggas terdapat 322 baris yang memiliki nilai 0 dan terakhir pada makanan minyak kelapa sawit terdapat 333 baris yang memiliki nilai 0.

Seluruh baris tersebut tidak di drop karena responden bisa jadi tidak mengkonsumsi makanan tersebut pada hari tersebut.
"""

# Subset kolom emisi
emission_columns = ['distanced_car',	'emissions_car',	'distanced_motor',	'emissions_motor',	'distanced_bus',	'emissions_bus']

# Melihat korelasi antarkolom dengan kolom total_emissions
sns.heatmap(df[emission_columns + ['total_emissions']].corr(), annot=True)
plt.show()

# Daftar vehicle yang ingin dianalisis
vehicle_list = ['car', 'motor', 'bus']

# Meloop melalui setiap kendaraan
for vehicle in vehicle_list:
    # Subset kolom fitur
    features = df[[f'distanced_{vehicle}']]

    # Menerapkan PCA pada fitur
    pca = PCA(n_components=1)
    transformed_features = pca.fit_transform(features)

    # Membuat DataFrame baru dari hasil PCA
    pca_df = pd.DataFrame(data=transformed_features, columns=['PC1'])

    # Menambahkan kolom target
    pca_df['emissions'] = df[f'emissions_{vehicle}']

    # Melihat korelasi antar kolom dengan heatmap
    sns.heatmap(pca_df.corr(), annot=True)
    plt.title(f'PCA Correlation Heatmap for {vehicle}')
    plt.show()

"""# Build Predict Model

## Car

Build the model to prediction emissions carbon to car
"""

# Separate features and target for car
car_features = df[['distanced_car']]
car_target = df['emissions_car']

# Split the beras data into training and testing sets
car_X_train, car_X_test, car_y_train, car_y_test = train_test_split(car_features, car_target, test_size=0.2, random_state=42)

# Create a Sequential model for car
car_model = Sequential()
car_model.add(Dense(16, input_dim=car_X_train.shape[1], activation=None))
car_model.add(Dropout(0.2))
car_model.add(Dense(8, activation=None))
car_model.add(Dropout(0.2))
car_model.add(Dense(1, activation=None))

# Compile the model with MAE and MSE as metrics
car_model.compile(loss='mean_absolute_error', optimizer=Adam(), metrics=['mae', 'mse'])

# Create EarlyStopping callback
early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_mse', patience=5)

# Train the model with callbacks
history = car_model.fit(car_X_train, car_y_train, validation_data=(car_X_test, car_y_test), epochs=20, callbacks=[early_stopping])

# Evaluate the model
loss, mae, mse = car_model.evaluate(car_X_test, car_y_test)
car_y_pred = car_model.predict(car_X_test)

# Calculate R-squared
r_squared = r2_score(car_y_test, car_y_pred)

# Print the accuracy report and R-squared
print("Accuracy Report:")
print("Mean Absolute Error (MAE):", mae)
print("Mean Squared Error (MSE):", mse)
print("R-squared:", r_squared)

# Print the loss and validation loss
loss_val = history.history['loss']
val_loss = history.history['val_loss']
print("Loss:", loss_val)
print("Validation Loss:", val_loss)

"""Save our model"""

# Set the file paths for saving the models
h5_model_path = '/content/drive/MyDrive/Vehicle_Greenix/new_model/mobil/car_model.h5'
tflite_model_path = '/content/drive/MyDrive/Vehicle_Greenix/new_model/mobil/car_model.tflite'
json_model_path = '/content/drive/MyDrive/Vehicle_Greenix/new_model/mobil/car_model.json'
bin_model_path = '/content/drive/MyDrive/Vehicle_Greenix/new_model/mobil/car_model.bin'
tensorflow_model_path = '/content/drive/MyDrive/Vehicle_Greenix/new_model/mobil/car_model.tensorflow'
tensorflowjs_model_path = '/content/drive/MyDrive/Vehicle_Greenix/new_model/mobil/tfjs_model'

# Save model in h5 format
car_model.save(h5_model_path)

# Save model in TensorFlow SavedModel format
tf.saved_model.save(car_model, tensorflow_model_path)

# Save model in TFLite format
converter = tf.lite.TFLiteConverter.from_keras_model(car_model)
tflite_model = converter.convert()
with open(tflite_model_path, 'wb') as f:
    f.write(tflite_model)

# Save model in JSON format
model_json = car_model.to_json()
with open(json_model_path, 'w') as f:
    f.write(model_json)

# Save model weights in binary format
car_model.save_weights(bin_model_path)

# Save model in TensorFlow.js format
tfjs.converters.save_keras_model(car_model, tensorflowjs_model_path)

# Mount Google Drive
drive.mount('/content/drive')

"""Make Prediction to New Data"""

# Load the model that has been saved
car_model = load_model('/content/drive/MyDrive/Vehicle_Greenix/new_model/mobil/car_model.h5')

# Convert the string input to a float
distanced_car_new = float(input("Masukkan Jarak Tempuh: "))

# Create a DataFrame with the new data
car_data_baru = pd.DataFrame({'distanced_car': [distanced_car_new]})

# Perform the prediction using the model
prediksi_car = car_model.predict(car_data_baru)

# Print the result of the prediction
print("Hasil prediksi konsumsi Model:")
print(prediksi_car)

"""## Sepeda Motor

Build the model to prediction emissions carbon to motorcyle
"""

# Separate features and target for motor
motor_features = df[['distanced_motor']]
motor_target = df['emissions_motor']

# Split the beras data into training and testing sets
motor_X_train, motor_X_test, motor_y_train, motor_y_test = train_test_split(motor_features, motor_target, test_size=0.2, random_state=42)

# Create a Sequential model for motor
motor_model = Sequential()
motor_model.add(Dense(64, input_dim=car_X_train.shape[1], activation=None))
motor_model.add(Dropout(0.2))
motor_model.add(Dense(32, activation=None))
motor_model.add(Dropout(0.2))
motor_model.add(Dense(1, activation=None))

# Compile the model with MAE and MSE as metrics
motor_model.compile(loss='mean_absolute_error', optimizer=Adam(), metrics=['mae', 'mse'])

# Create EarlyStopping callback
early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_mse', patience=5)

# Train the model with callbacks
history = motor_model.fit(car_X_train, car_y_train, validation_data=(car_X_test, car_y_test), epochs=20, callbacks=[early_stopping])

# Evaluate the model
loss, mae, mse = motor_model.evaluate(motor_X_test, motor_y_test)
motor_y_pred = motor_model.predict(motor_X_test)

# Calculate R-squared
r_squared = r2_score(motor_y_test, motor_y_pred)

# Print the accuracy report and R-squared
print("Accuracy Report:")
print("Mean Absolute Error (MAE):", mae)
print("Mean Squared Error (MSE):", mse)
print("R-squared:", r_squared)

# Print the loss and validation loss
loss_val = history.history['loss']
val_loss = history.history['val_loss']
print("Loss:", loss_val)
print("Validation Loss:", val_loss)

"""Save our model"""

# Set the file paths for saving the models
h5_model_path = '/content/drive/MyDrive/Vehicle_Greenix/new_model/motor/motor_model.h5'
tflite_model_path = '/content/drive/MyDrive/Vehicle_Greenix/new_model/motor/motor_model.tflite'
json_model_path = '/content/drive/MyDrive/Vehicle_Greenix/new_model/motor/motor_model.json'
bin_model_path = '/content/drive/MyDrive/Vehicle_Greenix/new_model/motor/motor_model.bin'
tensorflow_model_path = '/content/drive/MyDrive/Vehicle_Greenix/new_model/motor/motor_model.tensorflow'
tensorflowjs_model_path = '/content/drive/MyDrive/Vehicle_Greenix/new_model/motor/tfjs_model'

# Save model in h5 format
motor_model.save(h5_model_path)

# Save model in TensorFlow SavedModel format
tf.saved_model.save(motor_model, tensorflow_model_path)

# Save model in TFLite format
converter = tf.lite.TFLiteConverter.from_keras_model(motor_model)
tflite_model = converter.convert()
with open(tflite_model_path, 'wb') as f:
    f.write(tflite_model)

# Save model in JSON format
model_json = motor_model.to_json()
with open(json_model_path, 'w') as f:
    f.write(model_json)

# Save model weights in binary format
motor_model.save_weights(bin_model_path)

# Save model in TensorFlow.js format
tfjs.converters.save_keras_model(motor_model, tensorflowjs_model_path)

# Mount Google Drive
drive.mount('/content/drive')

"""Make Prediction to New Data"""

# Load the model that has been saved
motor_model = load_model('/content/drive/MyDrive/Vehicle_Greenix/new_model/motor/motor_model.h5')

# Convert the string input to a float
distanced_motor_new = float(input("Masukkan Jarak Tempuh: "))

# Create a DataFrame with the new data
motor_data_baru = pd.DataFrame({'distanced_motor': [distanced_motor_new]})

# Perform the prediction using the model
prediksi_motor = motor_model.predict(motor_data_baru)

# Print the result of the prediction
print("Hasil prediksi konsumsi Model:")
print(prediksi_motor)

"""## Bus

Build the model to prediction emissions carbon to bus
"""

# Separate features and target for bus
bus_features = df[['distanced_bus']]
bus_target = df['emissions_bus']

# Split the beras data into training and testing sets
bus_X_train, bus_X_test, bus_y_train, bus_y_test = train_test_split(bus_features, bus_target, test_size=0.2, random_state=42)

# Create a Sequential model for bus
bus_model = Sequential()
bus_model.add(Dense(64, input_dim=car_X_train.shape[1], activation=None))
bus_model.add(Dropout(0.2))
bus_model.add(Dense(32, activation=None))
bus_model.add(Dropout(0.2))
bus_model.add(Dense(1, activation=None))

# Compile the model with MAE and MSE as metrics
bus_model.compile(loss='mean_absolute_error', optimizer=Adam(), metrics=['mae', 'mse'])

# Create EarlyStopping callback
early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_mse', patience=5)

# Train the model with callbacks
history = motor_model.fit(bus_X_train, bus_y_train, validation_data=(bus_X_test, bus_y_test), epochs=20, callbacks=[early_stopping])

# Evaluate the model
loss, mae, mse = bus_model.evaluate(bus_X_test, bus_y_test)
bus_y_pred = bus_model.predict(bus_X_test)

# Calculate R-squared
r_squared = r2_score(bus_y_test, bus_y_pred)

# Print the accuracy report and R-squared
print("Accuracy Report:")
print("Mean Absolute Error (MAE):", mae)
print("Mean Squared Error (MSE):", mse)
print("R-squared:", r_squared)

# Print the loss and validation loss
loss_val = history.history['loss']
val_loss = history.history['val_loss']
print("Loss:", loss_val)
print("Validation Loss:", val_loss)

"""Save our model"""

# Set the file paths for saving the models
h5_model_path = '/content/drive/MyDrive/Vehicle_Greenix/new_model/motor/motor_model.h5'
tflite_model_path = '/content/drive/MyDrive/Vehicle_Greenix/new_model/motor/motor_model.tflite'
json_model_path = '/content/drive/MyDrive/Vehicle_Greenix/new_model/motor/motor_model.json'
bin_model_path = '/content/drive/MyDrive/Vehicle_Greenix/new_model/motor/motor_model.bin'
tensorflow_model_path = '/content/drive/MyDrive/Vehicle_Greenix/new_model/motor/motor_model.tensorflow'
tensorflowjs_model_path = '/content/drive/MyDrive/Vehicle_Greenix/new_model/motor/tfjs_model'

# Save model in h5 format
bus_model.save(h5_model_path)

# Save model in TensorFlow SavedModel format
tf.saved_model.save(bus_model, tensorflow_model_path)

# Save model in TFLite format
converter = tf.lite.TFLiteConverter.from_keras_model(bus_model)
tflite_model = converter.convert()
with open(tflite_model_path, 'wb') as f:
    f.write(tflite_model)

# Save model in JSON format
model_json = motor_model.to_json()
with open(json_model_path, 'w') as f:
    f.write(model_json)

# Save model weights in binary format
bus_model.save_weights(bin_model_path)

# Save model in TensorFlow.js format
tfjs.converters.save_keras_model(bus_model, tensorflowjs_model_path)

# Mount Google Drive
drive.mount('/content/drive')

"""Make Prediction to New Data"""

# Load the model that has been saved
bus_model = load_model('/content/drive/MyDrive/Vehicle_Greenix/new_model/bus/bus_model.h5')

# Convert the string input to a float
distanced_bus_new = float(input("Masukkan Jarak Tempuh: "))

# Create a DataFrame with the new data
bus_data_baru = pd.DataFrame({'distanced_bus': [distanced_bus_new]})

# Perform the prediction using the model
prediksi_bus = bus_model.predict(bus_data_baru)

# Print the result of the prediction
print("Hasil prediksi Emisi Bus:")
print(prediksi_motor)